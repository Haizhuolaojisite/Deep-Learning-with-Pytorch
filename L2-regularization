You will start with l2-regularization, the most important regularization technique in machine learning. 

As you saw in the video, l2-regularization simply penalizes large weights, and thus enforces the network to use only small weights.

# Instantiate the network
model = Net()

# Instantiate the cross-entropy loss
criterion = nn.CrossEntropyLoss()

# Instantiate the Adam optimizer with learning_rate equals to 3e-4, and l2 regularization parameter equals to 0.001.
optimizer = optim.Adam(model.parameters(), lr=3e-4, weight_decay=0.001)
